{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_mnist_cnn_tf1.15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXP6pMUPSIbv",
        "outputId": "7cbbb96b-7645-4868-b762-87057a4c9884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y\n",
            "Uninstalling tensorflow-2.3.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.3.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.3.0\n",
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 41kB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.35.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 59.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=c0182626b186628ddabc2e94037194086a037e652e0946ac1fafa7df0c4674ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, keras-applications, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgqX8zhOS632",
        "outputId": "038d207d-7140-4540-f9fd-b4eeca7fddac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsO7tbveXJOa",
        "outputId": "b681f067-881b-4350-dc3d-a4e0fbe557d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "%reset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 그래프 초기화\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Raw Data Loading\n",
        "df = pd.read_csv('/content/drive/My Drive/Machine Learning/train.csv')\n",
        "\n",
        "# 결측치와 이상치는 없음\n",
        "# Data Split(Train data와 Test data 분리)\n",
        "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
        "train_test_split(df.drop('label', axis=1, inplace=False),\n",
        "                 df['label'],\n",
        "                 test_size=0.3,\n",
        "                 random_state=0)\n",
        "\n",
        "# Min-Max Normalization\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_data_train)\n",
        "x_data_train_norm = scaler.transform(x_data_train)\n",
        "x_data_test_norm = scaler.transform(x_data_test)\n",
        "\n",
        "del x_data_train, x_data_test\n",
        "\n",
        "### Tensorflow implementation ###\\\n",
        "sess = tf.Session()\n",
        "t_data_train_onehot = sess.run(tf.one_hot(t_data_train, depth=10))\n",
        "t_data_test_onehot = sess.run(tf.one_hot(t_data_test, depth=10))\n",
        "\n",
        "# Placeholder\n",
        "\n",
        "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
        "T = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
        "drop_rate = tf.placeholder(dtype=tf.float32)\n",
        "\n",
        "# Convolution\n",
        "\n",
        "# 입력데이터 형태부터 설정\n",
        "x_img = tf.reshape(X,[-1, 28, 28, 1])   # (이미지개수, height, width, channel)\n",
        "\n",
        "# convolution layer 1\n",
        "W1 = tf.Variable(tf.random.normal([3,3,1,32]))  # (filter height, \n",
        "                                                #  filter width, \n",
        "                                                #  filter channel, \n",
        "                                                #  filter 개수)\n",
        "L1 = tf.nn.conv2d(x_img,W1, strides=[1,1,1,1], padding='SAME')\n",
        "L1 = tf.nn.relu(L1)   # 이 작업의 결과 => activation map (None,28,28,32)\n",
        "\n",
        "# pooling layer1\n",
        "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "print('L1의 shape : {}'.format(L1.shape))\n",
        "\n",
        "# convolution layer 2\n",
        "W2 = tf.Variable(tf.random.normal([3,3,32,64]))  # (filter height, \n",
        "                                                 #  filter width, \n",
        "                                                 #  filter channel, \n",
        "                                                 #  filter 개수)\n",
        "\n",
        "L2 = tf.nn.conv2d(L1,W2, strides=[1,1,1,1], padding='SAME')\n",
        "L2 = tf.nn.relu(L2)   # 이 작업의 결과 => activation map \n",
        " \n",
        "# pooling layer 2\n",
        "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "print('L2의 shape : {}'.format(L2.shape))  # (?, 7, 7, 64)\n",
        "\n",
        "# FC에 넣어서 학습을 진행!\n",
        "# 그래서 FC layer에 넣기 위해 데이터를 Flatten처리\n",
        "\n",
        "L2 = tf.reshape(L2, [-1,7*7*64])\n",
        "\n",
        "# Weight & bias\n",
        "W3 = tf.get_variable('weight3', shape=[7*7*64,256],\n",
        "                     initializer=tf.contrib.layers.variance_scaling_initializer())\n",
        "b3 = tf.Variable(tf.random.normal([256]))\n",
        "_layer3 = tf.nn.relu(tf.matmul(L2,W3) + b3)\n",
        "layer3 = tf.nn.dropout(_layer3, rate=drop_rate)\n",
        "\n",
        "W4 = tf.get_variable('weight4', shape=[256,10],\n",
        "                     initializer=tf.contrib.layers.variance_scaling_initializer())\n",
        "b4 = tf.Variable(tf.random.normal([10]))\n",
        "\n",
        "# Hypothesis\n",
        "logit = tf.matmul(layer3,W4) + b4\n",
        "H = tf.nn.softmax(logit)\n",
        "\n",
        "# loss\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
        "                                                                 labels=T))\n",
        "\n",
        "# train\n",
        "train = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)\n",
        "\n",
        "# parameter\n",
        "num_of_epoch = 200\n",
        "batch_size = 100\n",
        "\n",
        "# 학습\n",
        "\n",
        "def run_train(sess, train_x, train_t):\n",
        "    print('### Starting Training ###')\n",
        "    # 초기화\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for step in range(num_of_epoch):\n",
        "        total_batch = int(train_x.shape[0] / batch_size)\n",
        "        for i in range(total_batch):\n",
        "            batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
        "            batch_t = train_t[i*batch_size:(i+1)*batch_size]\n",
        "            _, loss_val = sess.run([train,loss], feed_dict={X:batch_x, \n",
        "                                                            T:batch_t, \n",
        "                                                            drop_rate:0.4})\n",
        "        if step % 20 == 0:\n",
        "            print('Loss : {}'.format(loss_val))\n",
        "    print('### End Training ###')\n",
        "\n",
        "# Accuracy\n",
        "predict = tf.argmax(H,1)\n",
        "\n",
        "# sklearn의 classification_report를 이용한 성능평가\n",
        "run_train(sess,x_data_train_norm,t_data_train_onehot)\n",
        "target_names=['num 0','num 1','num 2','num 3','num 4','num 5','num 6','num 7','num 8','num 9']\n",
        "print(classification_report(t_data_test,\n",
        "                            sess.run(predict,\n",
        "                                     feed_dict={X:x_data_test_norm, \n",
        "                                                drop_rate:0 }),\n",
        "                            target_names=target_names))                       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
            "L1의 shape : (?, 14, 14, 32)\n",
            "L2의 shape : (?, 7, 7, 64)\n",
            "### Starting Training ###\n",
            "Loss : 0.33786097168922424\n",
            "Loss : 0.004860183224081993\n",
            "Loss : 0.00038143686833791435\n",
            "Loss : 0.00024877378018572927\n",
            "Loss : 3.695485162324985e-08\n",
            "Loss : 9.011918109536055e-07\n",
            "Loss : 2.4996570573421195e-06\n",
            "Loss : 0.001115302206017077\n",
            "Loss : 0.0\n",
            "Loss : 2.384185515680315e-09\n",
            "### End Training ###\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       num 0       0.99      0.99      0.99      1242\n",
            "       num 1       0.99      0.99      0.99      1429\n",
            "       num 2       0.98      0.99      0.99      1276\n",
            "       num 3       1.00      0.99      0.99      1298\n",
            "       num 4       0.99      0.99      0.99      1236\n",
            "       num 5       0.99      0.99      0.99      1119\n",
            "       num 6       0.98      1.00      0.99      1243\n",
            "       num 7       0.99      0.99      0.99      1334\n",
            "       num 8       0.99      0.98      0.98      1204\n",
            "       num 9       0.98      0.98      0.98      1219\n",
            "\n",
            "    accuracy                           0.99     12600\n",
            "   macro avg       0.99      0.99      0.99     12600\n",
            "weighted avg       0.99      0.99      0.99     12600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}