# PyTorch

* `Numpy`를 대체하면서 GPU 연산을 가능케 함
* 최대한의 유연성과 속도를 제공하는 딥러닝 프레임워크



## Tensor

* `Tensor`는 `Numpy`와 유사하며, GPU를 사용한 연산 가속을 가능케 함

```python
## Tensor 생성

torch.empyt(5, 3)					# 초기화되지 않은 5x3 행렬 생성
torch.rand(5, 3)					# 무작위로 초기화된 5x3 행렬 생성
torch.zeros(5, 3, dtype=torch.long)	# dtype이 long인 5x3 영행렬 생성
torch.tensor([1,2,3])				# 데이터를 입력하여 직접 tensor 생성

## 기존 tensor를 바탕으로 새로운 tensor 생성
## method는 사용자로부터 새로운 값을 받지 않는 한, 입력 tensor의 속성을 재사용

x = x.new_ones(5,3, dtype=torch.double)		# new_* method는 크기를 받음
print(x)

'''tensor([[1., 1., 1.],
           [1., 1., 1.],
           [1., 1., 1.],
           [1., 1., 1.],
           [1., 1., 1.]], dtype=torch.float64)'''

x = torch.rand_like(x, dtype=torch.float)	# dtype을 override
print(x)

'''tensor([[ 0.3484,  2.3687,  1.8913],
           [-0.4076,  0.3218,  2.5641],
           [ 0.5478, -0.1723, -0.4435],
           [-0.7180,  1.6165,  1.5621],
           [-0.8697, -0.4903,  0.0836]])'''

print(x.size())		# 행렬의 크기를 구할 때는 size()

'''torch.Size([5, 3])'''
```





## Tensor 연산

```python
## 덧셈
x = torch.rand(5, 3)
y = torch.rand(5, 3)

# 문법 1)
print(x + y)

'''tensor([[ 0.7611,  2.4082,  2.0882],
           [-0.0686,  0.7743,  2.6695],
           [ 1.2113,  0.6225,  0.2882],
           [ 0.1564,  1.8914,  1.6344],
           [-0.1153, -0.2768,  0.1673]])'''


# 문법 2)
result = torch.empty(5, 3)
torch.add(x, y, out=result)
print(result)

'''tensor([[ 0.7611,  2.4082,  2.0882],
           [-0.0686,  0.7743,  2.6695],
           [ 1.2113,  0.6225,  0.2882],
           [ 0.1564,  1.8914,  1.6344],
           [-0.1153, -0.2768,  0.1673]])'''

# 문법 3) in-place 방식
y.add_(x)
print(x)

'''tensor([[ 0.7611,  2.4082,  2.0882],
           [-0.0686,  0.7743,  2.6695],
           [ 1.2113,  0.6225,  0.2882],
           [ 0.1564,  1.8914,  1.6344],
           [-0.1153, -0.2768,  0.1673]])'''

### in-place방식으로 tensor의 값을 변경하는 연산에는 '_'가 붙음
### ex) x.copy_(y), x.t_()


## 인덱싱
print(x)

'''tensor([[ 0.3484,  2.3687,  1.8913],
           [-0.4076,  0.3218,  2.5641],
           [ 0.5478, -0.1723, -0.4435],
           [-0.7180,  1.6165,  1.5621],
           [-0.8697, -0.4903,  0.0836]])'''

print(x[:, 1])
'''tensor([ 2.3687,  0.3218, -0.1723,  1.6165, -0.4903])'''

## 크기 변경
## tensor의 size 혹은 shape을 변경하고 싶다면 torch.view 사용
x = torch.randn(4, 4)
y = x.view(16)
z = x.view(-1, 8)
print(x.size(), y.size(), z.size())
'''torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])'''

## 만약 tensor에 단일값만 존재한다면, .item()으로 숫자값 그대로 받을 수 있음
x = torch.randn(1)
print(x)
'''tensor([0.8994])'''
print(x.item())
'''0.8994463682174683'''
```



## Numpy 변환

```python
## Tensor를 Numpy로 변환 -> .numpy()
a = torch.ones(5)
print(a)
'''tensor([1., 1., 1., 1., 1.])'''

b = a.numpy()
print(b)
'''[1. 1. 1. 1. 1.]'''

# Torch Tensor와 NumPy 배열은 메모리 공간을 공유하기 때문에 
# 하나를 변경하면 다른 하나도 변경됨
a.add_(1)
print(a)
'''tensor([2., 2., 2., 2., 2.])'''
print(b)
'''[2. 2. 2. 2. 2.]'''

## Numpy를 Tensor로 변환 -> .from_numpy()
import numpy as np
a = np.ones(5)
b = torch.from_numpy(a)
np.add(a, 1. out=a)

print(a)
'''[2. 2. 2. 2. 2.]'''
print(b)
'''tensor([2., 2., 2., 2., 2.], dtype=torch.float64)'''


## Tensor 장치 이동 -> .to()
# torch.device() 를 사용하여 tensor를 GPU 안팎으로 이동
if torch.cuda.is_available():
    device = torch.device("cuda")          # CUDA 장치 선언
    y = torch.ones_like(x, device=device)  # GPU 상에 직접적으로 tensor를 생성
    x = x.to(device)                       # .to()로도 이동 가능
    z = x + y
    print(z)
    '''tensor([1.8994], device='cuda:0')'''
    print(z.to("cpu", torch.double))       # .to() 는 dtype도 함께 변경
    '''tensor([1.8994], dtype=torch.float64)'''
```

